### **Governance Process for GitHub Copilot Usage**  

To ensure compliance with regulatory requirements and mitigate potential risks, our organization has established a governance framework for the use of GitHub Copilot in test automation. All testers must complete an attestation process to confirm their understanding of the associated risks and permitted usage. Copilot is strictly limited to generating test code and test data, with clear restrictions on handling confidential information and deploying AI-generated code to production. These guidelines are in place to align with legal and compliance obligations while enabling the safe and effective use of AI-assisted development.

### **GitHub Copilot Usage Guidelines for Test Automation in Our Bank**  

- **Mandatory Attestation Process** – All automation testers must complete an attestation process to acknowledge and understand the risks associated with using GitHub Copilot.  
- **Restricted Usage Scope** – Copilot may only be used to generate **test code** and **test data**. Any other use, including development of production code, is strictly prohibited.  
- **Confidentiality Compliance** – Under no circumstances should confidential, sensitive, or proprietary information be entered into Copilot. This includes customer data, internal algorithms, or business logic.  
- **No Deployment to Production** – Test code generated with Copilot **must not be deployed** in any production environment. This restriction is due to potential legal and compliance implications.  
- **Legal and Compliance Considerations** – The limitations on Copilot usage stem from regulatory requirements and legal risks associated with AI-generated code.  
- **Accountability and Review** – Users remain fully responsible for reviewing and validating all Copilot-generated test scripts to ensure correctness and compliance with internal security policies.  

Would you like me to refine any points or add further clarifications?
